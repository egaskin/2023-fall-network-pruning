{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-eC-sb34T9w"
      },
      "source": [
        "## Accelerate Inference: Neural Network Pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L47XBZWm4T9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "583fd387-8327-4fdc-e883-76f5f19e6d40"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from google.colab import files\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets,layers, models, regularizers\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "print(tf.version.VERSION)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount the drive\n",
        "from google.colab import drive\n",
        "drive_path_primitive = \"/content/drive/\"\n",
        "drive.mount(drive_path_primitive)\n",
        "\n",
        "drive_path = drive_path_primitive + \"MyDrive/ml-large-datasets-project/\"\n",
        "\n",
        "# use \"shutil\" to bring data and previous model into local memory\n",
        "import shutil\n",
        "src_data = drive_path + \"dataset.tar.gz\"\n",
        "shutil.copy(src = src_data, dst = \"./dataset.tar.gz\")\n",
        "\n",
        "load_previous_model = True\n",
        "model_name = \"model-start-v1.keras\"\n",
        "# model_name = \"model-network-slim-step1of2.keras\"\n",
        "src_model = drive_path + \"/\" + model_name\n",
        "shutil.copy(src = src_model, dst = \"./\" + model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "SZSQKqlZGNt_",
        "outputId": "9e9270ae-772f-4138-9626-cf89bf681366"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./model-start-v1.keras'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1FQTVeAuNiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ce32442-9f13-4ac5-d26b-ded8c565bf26"
      },
      "source": [
        "# untar\n",
        "!tar -xvzf dataset.tar.gz\n",
        "# load train\n",
        "train_images = pickle.load(open('train_images.pkl', 'rb'))\n",
        "train_labels = pickle.load(open('train_labels.pkl', 'rb'))\n",
        "# load val\n",
        "val_images = pickle.load(open('val_images.pkl', 'rb'))\n",
        "val_labels = pickle.load(open('val_labels.pkl', 'rb'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_images.pkl\n",
            "train_labels.pkl\n",
            "val_images.pkl\n",
            "val_labels.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE9JuZDG4T94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b116972-1658-48fd-e20f-7f0b7d9ac9ee"
      },
      "source": [
        "# Define the neural network architecture (don't change this)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-5), input_shape=(25,25,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "print(model.summary())\n",
        "total_trainable_params_original = 592933"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 25, 25, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 25, 25, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 23, 23, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 23, 23, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 11, 11, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 11, 11, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 11, 11, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 9, 9, 64)          36928     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 9, 9, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 4, 4, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               524800    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 592933 (2.26 MB)\n",
            "Trainable params: 592933 (2.26 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Nk_MAPqZPt"
      },
      "source": [
        "if load_previous_model:\n",
        "  # load previous model from the working directory\n",
        "  # note that the model should be uploaded to the working directory\n",
        "  model = keras.models.load_model(model_name)\n",
        "else:\n",
        "  # you can use the default hyper-parameters for training,\n",
        "  # val accuracy ~72% after 50 epochs\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, weight_decay=1e-6),\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  history = model.fit(train_images, train_labels, batch_size=32, epochs=50,\n",
        "                      validation_data=(val_images, val_labels)) # train for 50 epochs, with batch size 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOhpP7M24T9_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03cb1b7a-6c95-42f2-c8f8-c29d5d79fdf7"
      },
      "source": [
        "results = model.evaluate(val_images, val_labels, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 3s 17ms/step - loss: 0.7373 - accuracy: 0.7180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjw94aij4T-C"
      },
      "source": [
        "# perform pruning here - SEE ALL CELLS BELOW\n",
        "\n",
        "# get the weights\n",
        "weights = model.get_weights()\n",
        "\n",
        "# you can use set_weights() to set some weights to zero, e.g.,\n",
        "\n",
        "weights[7][:10]=0\n",
        "model.set_weights(weights)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# temporarily add intervening layers for batch normalization, see the\n",
        "# \"Leveraging the Scaling Factors in BN Layers\" section in paper\n",
        "\n",
        "# Define the neural network architecture (don't change this)\n",
        "temp_model = models.Sequential()\n",
        "temp_model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-5), input_shape=(25,25,3)))\n",
        "i = 0\n",
        "temp_model.add(BatchNormalization(gamma_regularizer=regularizers.l1(1e-5), center=False,name=f\"temp_layer_{i}\"))\n",
        "i += 1\n",
        "temp_model.add(Activation('relu'))\n",
        "temp_model.add(Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(1e-5)))\n",
        "temp_model.add(BatchNormalization(gamma_regularizer=regularizers.l1(1e-5), center=False,name=f\"temp_layer_{i}\"))\n",
        "i += 1\n",
        "temp_model.add(Activation('relu'))\n",
        "temp_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "temp_model.add(Dropout(0.25))\n",
        "temp_model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-5)))\n",
        "temp_model.add(BatchNormalization(gamma_regularizer=regularizers.l1(1e-5), center=False,name=f\"temp_layer_{i}\"))\n",
        "i += 1\n",
        "temp_model.add(Activation('relu'))\n",
        "temp_model.add(Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(1e-5)))\n",
        "temp_model.add(BatchNormalization(gamma_regularizer=regularizers.l1(1e-5), center=False,name=f\"temp_layer_{i}\"))\n",
        "i += 1\n",
        "temp_model.add(Activation('relu'))\n",
        "temp_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "temp_model.add(Dropout(0.25))\n",
        "temp_model.add(Flatten())\n",
        "temp_model.add(Dense(512))\n",
        "temp_model.add(BatchNormalization(gamma_regularizer=regularizers.l1(1e-5), center=False,name=f\"temp_layer_{i}\"))\n",
        "i += 1\n",
        "temp_model.add(Activation('relu'))\n",
        "temp_model.add(Dropout(0.5))\n",
        "temp_model.add(Dense(5))\n",
        "temp_model.add(BatchNormalization(gamma_regularizer=regularizers.l1(1e-5), center=False,name=f\"temp_layer_{i}\"))\n",
        "i += 1\n",
        "temp_model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "Kn9LSOrfNcWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_batch_norm = 6\n",
        "check = 0\n",
        "for layer_idx, layer in enumerate(temp_model.layers):\n",
        "  # print(layer_idx, layer)\n",
        "  if \"temp\" in layer.name:\n",
        "    check += 1\n",
        "assert check == number_batch_norm, f\"There should be {number_batch_norm} layers!\""
      ],
      "metadata": {
        "id": "6CYwTCUnVnwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(temp_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9sh24l7PVzM",
        "outputId": "2ddc1311-d1b8-4525-e1ea-fac3c005eae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 25, 25, 32)        896       \n",
            "                                                                 \n",
            " temp_layer_0 (BatchNormali  (None, 25, 25, 32)        96        \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 25, 25, 32)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 23, 23, 32)        9248      \n",
            "                                                                 \n",
            " temp_layer_1 (BatchNormali  (None, 23, 23, 32)        96        \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 23, 23, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 11, 11, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 11, 11, 32)        0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " temp_layer_2 (BatchNormali  (None, 11, 11, 64)        192       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 11, 11, 64)        0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 9, 9, 64)          36928     \n",
            "                                                                 \n",
            " temp_layer_3 (BatchNormali  (None, 9, 9, 64)          192       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 9, 9, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 4, 4, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " temp_layer_4 (BatchNormali  (None, 512)               1536      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            " temp_layer_5 (BatchNormali  (None, 5)                 15        \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 595060 (2.27 MB)\n",
            "Trainable params: 593642 (2.26 MB)\n",
            "Non-trainable params: 1418 (5.54 KB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_previous_temp_model = True\n",
        "previous_temp_model_name = \"temp-model.keras\"\n",
        "\n",
        "if not load_previous_temp_model:\n",
        "\n",
        "  # re-train the temporary model, leveraging the Batch Normalization layers\n",
        "  # to get the channel scaling factors\n",
        "  # \"Leveraging the Scaling Factors in BN Layers\" section in paper\n",
        "\n",
        "  temp_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, weight_decay=1e-6),\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  history_temp = temp_model.fit(train_images, train_labels, batch_size=32, epochs=50,\n",
        "                        validation_data=(val_images, val_labels)) # train for 50 epochs, with batch size 32\n",
        "else:\n",
        "  # copy the temp_model from drive into the local memory and load the model\n",
        "  src_temp_model = drive_path + \"/\" + previous_temp_model_name\n",
        "  shutil.copy(src = src_temp_model, dst = \"./\" + previous_temp_model_name)\n",
        "  temp_model = keras.models.load_model(previous_temp_model_name)"
      ],
      "metadata": {
        "id": "XgUhbgUvRD7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GOAL: identify channels which need pruned for each layer in the original model\n",
        "ready_to_prune_1 = False\n",
        "ready_to_prune_2 = False\n",
        "for layer_idx, layer in enumerate(temp_model.layers):\n",
        "  if \"temp\" not in layer.name:\n",
        "    # print(layer)\n",
        "    layer_to_prune = layer\n",
        "    ready_to_prune_1 = True\n",
        "  elif  \"temp\" in layer.name:\n",
        "    # print(layer)\n",
        "    batch_norm_layer = layer\n",
        "    ready_to_prune_2 = True\n",
        "\n",
        "  # see if we've collected both pairs\n",
        "  if ready_to_prune_1 and ready_to_prune_2:\n",
        "      print(layer_to_prune.name,batch_norm_layer.name)\n",
        "      # reset it\n",
        "      ready_to_prune_1 = False\n",
        "      ready_to_prune_2 = False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUZp8a1FUhnN",
        "outputId": "6eb81c86-6fd9-4a35-949f-9bdae2ebc321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv2d_4 temp_layer_0\n",
            "conv2d_5 temp_layer_1\n",
            "conv2d_6 temp_layer_2\n",
            "conv2d_7 temp_layer_3\n",
            "dense_2 temp_layer_4\n",
            "dense_3 temp_layer_5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GOAL: identify channels which need pruned for each layer in the original model\n",
        "# STEP 1: calculate global percentile bins.\n",
        "# 1a. get min and max\n",
        "\n",
        "# initialize them\n",
        "max_gamma = -np.inf\n",
        "min_gamma = np.inf\n",
        "\n",
        "for layer_idx, layer in enumerate(temp_model.layers):\n",
        "  # print(temp_model.layers[layer_idx-1].name)\n",
        "\n",
        "  if  \"temp\" in layer.name and \"dense_2\" == temp_model.layers[layer_idx-1].name:\n",
        "  # if  \"temp\" in layer.name and \"dense_3\" != temp_model.layers[layer_idx-1].name:\n",
        "    # print(layer.name)\n",
        "    batch_norm_layer = layer\n",
        "\n",
        "    # https://stackoverflow.com/questions/42521005/how-the-number-of-parameters-associated-with-batchnormalization-layer-is-2048\n",
        "    gamma_weights = batch_norm_layer.weights[0]\n",
        "\n",
        "    # https://stackoverflow.com/questions/70043645/how-to-convert-from-tensor-to-float\n",
        "    layer_max_gamma = tf.reduce_max(gamma_weights).numpy()\n",
        "    layer_min_gamma = tf.reduce_min(gamma_weights).numpy()\n",
        "\n",
        "    if layer_max_gamma > max_gamma:\n",
        "      max_gamma = layer_max_gamma\n",
        "\n",
        "    if layer_min_gamma < min_gamma:\n",
        "      min_gamma = layer_min_gamma\n",
        "  # elif \"temp\" in layer.name and \"dense_2\" not in layer.name:\n",
        "\n",
        "\n",
        "print(min_gamma,max_gamma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d40dcc8-ed97-47af-ef48-3ca11446f7ff",
        "id": "vS1uJQ-ybEFG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9195836 1.0561795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step 1b. calculate the percentiles\n",
        "\n",
        "q = np.arange(0,100,1)\n",
        "\n",
        "print(q)\n",
        "\n",
        "percentiles = np.percentile(a = [min_gamma,max_gamma], q=q)\n",
        "\n",
        "print(percentiles)\n",
        "print(len(percentiles))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScK3cgs6KtvB",
        "outputId": "8f2e2fe0-96e8-44b6-8be3-f9e3d7c89b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
            " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
            " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
            " 96 97 98 99]\n",
            "[0.91958362 0.92094958 0.92231554 0.9236815  0.92504745 0.92641341\n",
            " 0.92777937 0.92914533 0.93051129 0.93187725 0.93324321 0.93460917\n",
            " 0.93597513 0.93734109 0.93870705 0.940073   0.94143896 0.94280492\n",
            " 0.94417088 0.94553684 0.9469028  0.94826876 0.94963472 0.95100068\n",
            " 0.95236664 0.95373259 0.95509855 0.95646451 0.95783047 0.95919643\n",
            " 0.96056239 0.96192835 0.96329431 0.96466027 0.96602623 0.96739219\n",
            " 0.96875814 0.9701241  0.97149006 0.97285602 0.97422198 0.97558794\n",
            " 0.9769539  0.97831986 0.97968582 0.98105178 0.98241773 0.98378369\n",
            " 0.98514965 0.98651561 0.98788157 0.98924753 0.99061349 0.99197945\n",
            " 0.99334541 0.99471137 0.99607733 0.99744328 0.99880924 1.0001752\n",
            " 1.00154116 1.00290712 1.00427308 1.00563904 1.007005   1.00837096\n",
            " 1.00973692 1.01110287 1.01246883 1.01383479 1.01520075 1.01656671\n",
            " 1.01793267 1.01929863 1.02066459 1.02203055 1.02339651 1.02476247\n",
            " 1.02612842 1.02749438 1.02886034 1.0302263  1.03159226 1.03295822\n",
            " 1.03432418 1.03569014 1.0370561  1.03842206 1.03978801 1.04115397\n",
            " 1.04251993 1.04388589 1.04525185 1.04661781 1.04798377 1.04934973\n",
            " 1.05071569 1.05208165 1.05344761 1.05481356]\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# METHOD FOR GENERATING A SINGLE PERCENTILE\n",
        "\n",
        "desired_percentile = 59\n",
        "\n",
        "idx_desired_percentile = np.where(q==desired_percentile)\n",
        "\n",
        "cutoff_gamma = percentiles[idx_desired_percentile]\n",
        "print(\"cutoff_gamma = \",cutoff_gamma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccm9MxwMLnpT",
        "outputId": "359cd5af-9946-4523-cd3b-ac0ebb4f42e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cutoff_gamma =  [1.0001752]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step 1b. calculate the percentiles\n",
        "num_cutoffs_desired = 10\n",
        "\n",
        "all_cutoffs = np.linspace(min_gamma,max_gamma,num_cutoffs_desired)\n",
        "\n",
        "print(\"all_cutoffs\",all_cutoffs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3vKwHxzcvPa",
        "outputId": "c4eedabf-1c2d-44a0-c915-4717f440499d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all_cutoffs [0.91958362 0.93476094 0.94993826 0.96511559 0.98029291 0.99547023\n",
            " 1.01064756 1.02582488 1.0410022  1.05617952]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sparsity_vs_accuracy_list = []\n",
        "\n",
        "# STEP 2: using the thresholds from above, perform pruning on the channels\n",
        "retrain_pruned_model_bool = True\n",
        "number_retraining_epochs = 10\n",
        "for cutoff_gamma in all_cutoffs:\n",
        "  print(\"cutoff_gamma = \", cutoff_gamma)\n",
        "\n",
        "  if load_previous_temp_model:\n",
        "    temp_model = keras.models.load_model(previous_temp_model_name)\n",
        "  else:\n",
        "    print(\"\"\"BE SURE TO RE-GENERATE ORIGINAL TEMP MODEL BEFORE THIS,\n",
        "          if you want to see the actual before and after calcs!!!\"\"\")\n",
        "\n",
        "  # GOAL: identify channels which need pruned for each layer in the original model\n",
        "  # Step 2: prune based on the selected percentile\n",
        "  ready_to_prune_1 = False\n",
        "  ready_to_prune_2 = False\n",
        "  total_pruned = 0\n",
        "  for layer_idx, layer in enumerate(temp_model.layers):\n",
        "    if \"temp\" not in layer.name:\n",
        "      # print(layer)\n",
        "      layer_to_prune = layer\n",
        "      ready_to_prune_1 = True\n",
        "    elif  \"temp\" in layer.name:\n",
        "      # print(layer)\n",
        "      batch_norm_layer = layer\n",
        "      ready_to_prune_2 = True\n",
        "\n",
        "    # see if we've collected both pairs, if so, calculate the pruned weights\n",
        "    if ready_to_prune_1 and ready_to_prune_2:\n",
        "        weights_to_prune, bias_to_prune = layer_to_prune.get_weights()\n",
        "        bn_gamma_weights = batch_norm_layer.weights[0]\n",
        "\n",
        "        # BELOW REVEALS THAT the last Dense layer contains the max value\n",
        "        # print(\"tf.reduce_max(bn_gamma_weights)\",float(tf.reduce_max(bn_gamma_weights)))\n",
        "\n",
        "        channels_to_prune_idxs = np.where(bn_gamma_weights<cutoff_gamma)[0]\n",
        "        # print(channels_to_prune_idxs)\n",
        "\n",
        "        nonzero_params_before = np.count_nonzero(weights_to_prune) + np.count_nonzero(bias_to_prune)\n",
        "        print(\"nonzero_params_before\",nonzero_params_before)\n",
        "\n",
        "        for channel_idx in channels_to_prune_idxs:\n",
        "          # handle conv2D\n",
        "          if len(weights_to_prune.shape) == 4:\n",
        "            # print(\"WE SAW THIS\")\n",
        "            weights_to_prune[:,:,:,channel_idx] = 0\n",
        "            bias_to_prune[channel_idx] = 0\n",
        "          # handle Dense Layer\n",
        "          else:\n",
        "            # print(\"WE SAW THIS\")\n",
        "            weights_to_prune[:,channel_idx] = 0\n",
        "            bias_to_prune[channel_idx] = 0\n",
        "\n",
        "        nonzero_params_after = np.count_nonzero(weights_to_prune) + np.count_nonzero(bias_to_prune)\n",
        "        print(\"nonzero_params_after\",nonzero_params_after)\n",
        "\n",
        "        total_pruned += nonzero_params_before - nonzero_params_after\n",
        "\n",
        "\n",
        "        layer_to_prune.set_weights([weights_to_prune,bias_to_prune])\n",
        "        # print(channels_to_prune_idxs.shape)\n",
        "        # raise Exception(\"stop\")\n",
        "        # print(\"original weights shape\",[weight.shape for weight in layer_to_prune.weights])\n",
        "        # print(\"temp weights shape\",[weight.shape for weight in batch_norm_layer.weights])\n",
        "        # print(\"temp weights shape\",[weight[0:5] for weight in batch_norm_layer.weights])\n",
        "        # print()\n",
        "        # print(layer_to_prune.name,batch_norm_layer.name)\n",
        "        # raise Exception(\"STOP\")\n",
        "        # print(batch_norm_layer.weights)\n",
        "\n",
        "        # reset it\n",
        "        ready_to_prune_1 = False\n",
        "        ready_to_prune_2 = False\n",
        "\n",
        "\n",
        "  print(\"total_pruned:\",total_pruned)\n",
        "  print(\"total_trainable_params_original:\",total_trainable_params_original)\n",
        "  print(\"fraction pruned:\",total_pruned/total_trainable_params_original)\n",
        "\n",
        "  # perform the pruning using the current cutoff\n",
        "  new_model_weights = []\n",
        "  new_weights = temp_model.get_weights()\n",
        "  for l_idx, l in enumerate(new_weights):\n",
        "    if l_idx % 5 < 2:\n",
        "        new_model_weights.append(l)\n",
        "  # for m in new_model_weights:\n",
        "  #   print(m.shape)\n",
        "\n",
        "  model.set_weights(new_model_weights)\n",
        "\n",
        "  # evaluate again to see how the accuracy changes\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, weight_decay=1e-6),\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "  if retrain_pruned_model_bool:\n",
        "    # retrain for specified number of epochs, with batch size 32\n",
        "    history = model.fit(train_images, train_labels, batch_size=32, epochs=number_retraining_epochs,\n",
        "                          validation_data=(val_images, val_labels))\n",
        "\n",
        "    total_nonzero_after_retraining = sum([np.count_nonzero(weight_vec) for weight_vec in model.weights])\n",
        "    total_pruned = total_trainable_params_original - total_nonzero_after_retraining\n",
        "    sparsity = total_pruned/total_trainable_params_original\n",
        "    print(\"total_pruned, after retraining pruned:\",total_pruned)\n",
        "    print(\"total_trainable_params_original, after retraining pruned:\",total_trainable_params_original)\n",
        "    print(\"sparsity, after retraining pruned:\",sparsity)\n",
        "  else:\n",
        "    total_nonzero_after_retraining = sum([np.count_nonzero(weight_vec) for weight_vec in model.weights])\n",
        "    total_pruned = total_trainable_params_original - total_nonzero_after_retraining\n",
        "    sparsity = total_pruned/total_trainable_params_original\n",
        "    print(\"total_pruned, after NOT retraining pruned:\",total_pruned)\n",
        "    print(\"total_trainable_params_original, after NOT retraining pruned:\",total_trainable_params_original)\n",
        "    print(\"sparsity, after NOT retraining pruned:\",sparsity)\n",
        "\n",
        "  # you need to save the model's weights, naming it 'my_model_weights.h5'\n",
        "  save_name = f\"my_model_weights_network_slimming_cutoff_gamma_{cutoff_gamma}.h5\"\n",
        "  model.save_weights(save_name)\n",
        "  files.download(save_name)\n",
        "\n",
        "  # evaluate again to see how the accuracy changes\n",
        "  results = model.evaluate(val_images, val_labels, batch_size=128)\n",
        "  accuracy = results[1]\n",
        "\n",
        "  save_tuple = (accuracy, sparsity, cutoff_gamma)\n",
        "  sparsity_vs_accuracy_list.append(save_tuple)\n",
        "\n",
        "\n",
        "  print(\"finished cutoff_gamma = \", cutoff_gamma)\n",
        "  print(\"________________________________________________\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "enOkR6Gloj9r",
        "outputId": "b37f20e3-cf05-4745-8cf1-e96b5ac1b51e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cutoff_gamma =  0.9195836186408997\n",
            "nonzero_params_before 896\n",
            "nonzero_params_after 868\n",
            "nonzero_params_before 9248\n",
            "nonzero_params_after 8959\n",
            "nonzero_params_before 18496\n",
            "nonzero_params_after 17918\n",
            "nonzero_params_before 36928\n",
            "nonzero_params_after 36351\n",
            "nonzero_params_before 524800\n",
            "nonzero_params_after 524800\n",
            "nonzero_params_before 2565\n",
            "nonzero_params_after 2565\n",
            "total_pruned: 1472\n",
            "total_trainable_params_original: 592933\n",
            "fraction pruned: 0.0024825739164458715\n",
            "Epoch 1/10\n",
            "703/703 [==============================] - 7s 8ms/step - loss: 1.1003 - accuracy: 0.5669 - val_loss: 0.9273 - val_accuracy: 0.6507\n",
            "Epoch 2/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.8507 - accuracy: 0.6800 - val_loss: 0.8241 - val_accuracy: 0.6867\n",
            "Epoch 3/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.7952 - accuracy: 0.7036 - val_loss: 0.8107 - val_accuracy: 0.6879\n",
            "Epoch 4/10\n",
            "703/703 [==============================] - 5s 7ms/step - loss: 0.7595 - accuracy: 0.7151 - val_loss: 0.7327 - val_accuracy: 0.7255\n",
            "Epoch 5/10\n",
            "703/703 [==============================] - 5s 7ms/step - loss: 0.7357 - accuracy: 0.7272 - val_loss: 0.7276 - val_accuracy: 0.7366\n",
            "Epoch 6/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.7096 - accuracy: 0.7373 - val_loss: 0.7445 - val_accuracy: 0.7279\n",
            "Epoch 7/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.6991 - accuracy: 0.7394 - val_loss: 0.7565 - val_accuracy: 0.7176\n",
            "Epoch 8/10\n",
            "703/703 [==============================] - 5s 8ms/step - loss: 0.6850 - accuracy: 0.7473 - val_loss: 0.6871 - val_accuracy: 0.7521\n",
            "Epoch 9/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.6744 - accuracy: 0.7488 - val_loss: 0.6906 - val_accuracy: 0.7438\n",
            "Epoch 10/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.6493 - accuracy: 0.7587 - val_loss: 0.7259 - val_accuracy: 0.7251\n",
            "[0.7866467833518982, 0.7053465247154236]\n",
            "total_pruned, after retraining pruned: 1472\n",
            "total_trainable_params_original, after retraining pruned: 592933\n",
            "fraction pruned, after retraining pruned: 0.0024825739164458715\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0b546aaf-4659-476f-8f81-8c29c5b12b24\", \"my_model_weights_network_slimming_cutoff_gamma_0.9195836186408997.h5\", 2407040)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7259 - accuracy: 0.7251\n",
            "finished cutoff_gamma =  0.9195836186408997\n",
            "________________________________________________\n",
            "cutoff_gamma =  0.9347609413994683\n",
            "nonzero_params_before 896\n",
            "nonzero_params_after 812\n",
            "nonzero_params_before 9248\n",
            "nonzero_params_after 8670\n",
            "nonzero_params_before 18496\n",
            "nonzero_params_after 17918\n",
            "nonzero_params_before 36928\n",
            "nonzero_params_after 35774\n",
            "nonzero_params_before 524800\n",
            "nonzero_params_after 522750\n",
            "nonzero_params_before 2565\n",
            "nonzero_params_after 2565\n",
            "total_pruned: 4444\n",
            "total_trainable_params_original: 592933\n",
            "fraction pruned: 0.00749494462274827\n",
            "Epoch 1/10\n",
            "703/703 [==============================] - 8s 8ms/step - loss: 1.1135 - accuracy: 0.5602 - val_loss: 0.9200 - val_accuracy: 0.6451\n",
            "Epoch 2/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.8622 - accuracy: 0.6769 - val_loss: 0.8309 - val_accuracy: 0.6931\n",
            "Epoch 3/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.8136 - accuracy: 0.6942 - val_loss: 0.7602 - val_accuracy: 0.7236\n",
            "Epoch 4/10\n",
            "703/703 [==============================] - 5s 7ms/step - loss: 0.7725 - accuracy: 0.7093 - val_loss: 0.7668 - val_accuracy: 0.7046\n",
            "Epoch 5/10\n",
            "703/703 [==============================] - 5s 7ms/step - loss: 0.7421 - accuracy: 0.7240 - val_loss: 0.7963 - val_accuracy: 0.6982\n",
            "Epoch 6/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.7249 - accuracy: 0.7293 - val_loss: 0.8482 - val_accuracy: 0.6768\n",
            "Epoch 7/10\n",
            "703/703 [==============================] - 7s 10ms/step - loss: 0.7083 - accuracy: 0.7347 - val_loss: 0.7370 - val_accuracy: 0.7275\n",
            "Epoch 8/10\n",
            "703/703 [==============================] - 5s 7ms/step - loss: 0.6954 - accuracy: 0.7441 - val_loss: 0.7170 - val_accuracy: 0.7358\n",
            "Epoch 9/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.6782 - accuracy: 0.7469 - val_loss: 0.7443 - val_accuracy: 0.7121\n",
            "Epoch 10/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.6686 - accuracy: 0.7500 - val_loss: 0.7215 - val_accuracy: 0.7303\n",
            "[0.7259025573730469, 0.7251484990119934]\n",
            "total_pruned, after retraining pruned: 4444\n",
            "total_trainable_params_original, after retraining pruned: 592933\n",
            "fraction pruned, after retraining pruned: 0.00749494462274827\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_803e48fe-5fc9-49fe-ab38-5de30ffb80f0\", \"my_model_weights_network_slimming_cutoff_gamma_0.9347609413994683.h5\", 2407040)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7215 - accuracy: 0.7303\n",
            "finished cutoff_gamma =  0.9347609413994683\n",
            "________________________________________________\n",
            "cutoff_gamma =  0.949938264158037\n",
            "nonzero_params_before 896\n",
            "nonzero_params_after 756\n",
            "nonzero_params_before 9248\n",
            "nonzero_params_after 8381\n",
            "nonzero_params_before 18496\n",
            "nonzero_params_after 16473\n",
            "nonzero_params_before 36928\n",
            "nonzero_params_after 33466\n",
            "nonzero_params_before 524800\n",
            "nonzero_params_after 492000\n",
            "nonzero_params_before 2565\n",
            "nonzero_params_after 2565\n",
            "total_pruned: 39292\n",
            "total_trainable_params_original: 592933\n",
            "fraction pruned: 0.0662671836446951\n",
            "Epoch 1/10\n",
            "703/703 [==============================] - 7s 7ms/step - loss: 1.1621 - accuracy: 0.5357 - val_loss: 0.9412 - val_accuracy: 0.6372\n",
            "Epoch 2/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.9030 - accuracy: 0.6578 - val_loss: 0.8363 - val_accuracy: 0.6855\n",
            "Epoch 3/10\n",
            "703/703 [==============================] - 6s 8ms/step - loss: 0.8442 - accuracy: 0.6814 - val_loss: 0.8718 - val_accuracy: 0.6677\n",
            "Epoch 4/10\n",
            "703/703 [==============================] - 6s 9ms/step - loss: 0.8060 - accuracy: 0.6987 - val_loss: 0.7830 - val_accuracy: 0.7018\n",
            "Epoch 5/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.7795 - accuracy: 0.7076 - val_loss: 0.7930 - val_accuracy: 0.7002\n",
            "Epoch 6/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.7526 - accuracy: 0.7159 - val_loss: 0.7439 - val_accuracy: 0.7228\n",
            "Epoch 7/10\n",
            "703/703 [==============================] - 5s 7ms/step - loss: 0.7373 - accuracy: 0.7220 - val_loss: 0.7694 - val_accuracy: 0.7133\n",
            "Epoch 8/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.7180 - accuracy: 0.7317 - val_loss: 0.7395 - val_accuracy: 0.7192\n",
            "Epoch 9/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.7039 - accuracy: 0.7367 - val_loss: 0.7071 - val_accuracy: 0.7402\n",
            "Epoch 10/10\n",
            "703/703 [==============================] - 5s 6ms/step - loss: 0.6903 - accuracy: 0.7433 - val_loss: 0.7342 - val_accuracy: 0.7224\n",
            "[0.7215346693992615, 0.7302970290184021]\n",
            "total_pruned, after retraining pruned: 39292\n",
            "total_trainable_params_original, after retraining pruned: 592933\n",
            "fraction pruned, after retraining pruned: 0.0662671836446951\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_41b56e4f-247c-4c86-8dfd-3d3b5f266a53\", \"my_model_weights_network_slimming_cutoff_gamma_0.949938264158037.h5\", 2407040)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7342 - accuracy: 0.7224\n",
            "finished cutoff_gamma =  0.949938264158037\n",
            "________________________________________________\n",
            "cutoff_gamma =  0.9651155869166056\n",
            "nonzero_params_before 896\n",
            "nonzero_params_after 644\n",
            "nonzero_params_before 9248\n",
            "nonzero_params_after 8092\n",
            "nonzero_params_before 18496\n",
            "nonzero_params_after 14739\n",
            "nonzero_params_before 36928\n",
            "nonzero_params_after 30581\n",
            "nonzero_params_before 524800\n",
            "nonzero_params_after 423325\n",
            "nonzero_params_before 2565\n",
            "nonzero_params_after 2565\n",
            "total_pruned: 112987\n",
            "total_trainable_params_original: 592933\n",
            "fraction pruned: 0.19055609993034625\n",
            "Epoch 1/10\n",
            "703/703 [==============================] - 7s 6ms/step - loss: 1.1630 - accuracy: 0.5499 - val_loss: 0.9661 - val_accuracy: 0.6178\n",
            "Epoch 2/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.9400 - accuracy: 0.6436 - val_loss: 0.8669 - val_accuracy: 0.6756\n",
            "Epoch 3/10\n",
            "703/703 [==============================] - 5s 7ms/step - loss: 0.8821 - accuracy: 0.6653 - val_loss: 0.8692 - val_accuracy: 0.6618\n",
            "Epoch 4/10\n",
            "703/703 [==============================] - 5s 7ms/step - loss: 0.8498 - accuracy: 0.6797 - val_loss: 0.8206 - val_accuracy: 0.6887\n",
            "Epoch 5/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.8203 - accuracy: 0.6905 - val_loss: 0.7981 - val_accuracy: 0.7022\n",
            "Epoch 6/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.7940 - accuracy: 0.6983 - val_loss: 0.7891 - val_accuracy: 0.6970\n",
            "Epoch 7/10\n",
            "703/703 [==============================] - 5s 8ms/step - loss: 0.7746 - accuracy: 0.7112 - val_loss: 0.7782 - val_accuracy: 0.7085\n",
            "Epoch 8/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.7667 - accuracy: 0.7103 - val_loss: 0.7780 - val_accuracy: 0.7061\n",
            "Epoch 9/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.7488 - accuracy: 0.7177 - val_loss: 0.7353 - val_accuracy: 0.7307\n",
            "Epoch 10/10\n",
            "703/703 [==============================] - 5s 7ms/step - loss: 0.7341 - accuracy: 0.7227 - val_loss: 0.7909 - val_accuracy: 0.6986\n",
            "[0.7342305779457092, 0.7223762273788452]\n",
            "total_pruned, after retraining pruned: 112987\n",
            "total_trainable_params_original, after retraining pruned: 592933\n",
            "fraction pruned, after retraining pruned: 0.19055609993034625\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e34e1434-15b9-4a68-8a9e-602a1ff3e4e6\", \"my_model_weights_network_slimming_cutoff_gamma_0.9651155869166056.h5\", 2407040)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7909 - accuracy: 0.6986\n",
            "finished cutoff_gamma =  0.9651155869166056\n",
            "________________________________________________\n",
            "cutoff_gamma =  0.9802929096751742\n",
            "nonzero_params_before 896\n",
            "nonzero_params_after 560\n",
            "nonzero_params_before 9248\n",
            "nonzero_params_after 4913\n",
            "nonzero_params_before 18496\n",
            "nonzero_params_after 12716\n",
            "nonzero_params_before 36928\n",
            "nonzero_params_after 24811\n",
            "nonzero_params_before 524800\n",
            "nonzero_params_after 307500\n",
            "nonzero_params_before 2565\n",
            "nonzero_params_after 2565\n",
            "total_pruned: 239868\n",
            "total_trainable_params_original: 592933\n",
            "fraction pruned: 0.4045448642595369\n",
            "Epoch 1/10\n",
            "703/703 [==============================] - 8s 8ms/step - loss: 1.3267 - accuracy: 0.4481 - val_loss: 1.1461 - val_accuracy: 0.5382\n",
            "Epoch 2/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.1313 - accuracy: 0.5518 - val_loss: 1.1164 - val_accuracy: 0.5525\n",
            "Epoch 3/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.0638 - accuracy: 0.5805 - val_loss: 0.9809 - val_accuracy: 0.6166\n",
            "Epoch 4/10\n",
            "703/703 [==============================] - 5s 7ms/step - loss: 1.0155 - accuracy: 0.6060 - val_loss: 0.9562 - val_accuracy: 0.6317\n",
            "Epoch 5/10\n",
            "703/703 [==============================] - 5s 7ms/step - loss: 0.9788 - accuracy: 0.6222 - val_loss: 0.9567 - val_accuracy: 0.6238\n",
            "Epoch 6/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.9490 - accuracy: 0.6312 - val_loss: 0.8990 - val_accuracy: 0.6574\n",
            "Epoch 7/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.9258 - accuracy: 0.6408 - val_loss: 0.9088 - val_accuracy: 0.6451\n",
            "Epoch 8/10\n",
            "703/703 [==============================] - 5s 8ms/step - loss: 0.9088 - accuracy: 0.6545 - val_loss: 0.9110 - val_accuracy: 0.6448\n",
            "Epoch 9/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.8913 - accuracy: 0.6580 - val_loss: 0.8529 - val_accuracy: 0.6630\n",
            "Epoch 10/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.8739 - accuracy: 0.6631 - val_loss: 0.8401 - val_accuracy: 0.6867\n",
            "[0.7909043431282043, 0.6986138820648193]\n",
            "total_pruned, after retraining pruned: 239868\n",
            "total_trainable_params_original, after retraining pruned: 592933\n",
            "fraction pruned, after retraining pruned: 0.4045448642595369\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_08c43d4e-1e7d-403f-8d0c-1a368f999d33\", \"my_model_weights_network_slimming_cutoff_gamma_0.9802929096751742.h5\", 2407040)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 4ms/step - loss: 0.8401 - accuracy: 0.6867\n",
            "finished cutoff_gamma =  0.9802929096751742\n",
            "________________________________________________\n",
            "cutoff_gamma =  0.995470232433743\n",
            "nonzero_params_before 896\n",
            "nonzero_params_after 504\n",
            "nonzero_params_before 9248\n",
            "nonzero_params_after 4624\n",
            "nonzero_params_before 18496\n",
            "nonzero_params_after 8959\n",
            "nonzero_params_before 36928\n",
            "nonzero_params_after 21349\n",
            "nonzero_params_before 524800\n",
            "nonzero_params_after 193725\n",
            "nonzero_params_before 2565\n",
            "nonzero_params_after 2565\n",
            "total_pruned: 361207\n",
            "total_trainable_params_original: 592933\n",
            "fraction pruned: 0.6091868727158043\n",
            "Epoch 1/10\n",
            "703/703 [==============================] - 8s 8ms/step - loss: 1.4082 - accuracy: 0.3915 - val_loss: 1.2407 - val_accuracy: 0.4923\n",
            "Epoch 2/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.2404 - accuracy: 0.4877 - val_loss: 1.1780 - val_accuracy: 0.5141\n",
            "Epoch 3/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.1763 - accuracy: 0.5283 - val_loss: 1.1016 - val_accuracy: 0.5556\n",
            "Epoch 4/10\n",
            "703/703 [==============================] - 5s 8ms/step - loss: 1.1352 - accuracy: 0.5482 - val_loss: 1.0588 - val_accuracy: 0.5743\n",
            "Epoch 5/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.0939 - accuracy: 0.5659 - val_loss: 1.0496 - val_accuracy: 0.5838\n",
            "Epoch 6/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.0706 - accuracy: 0.5799 - val_loss: 1.0101 - val_accuracy: 0.6028\n",
            "Epoch 7/10\n",
            "703/703 [==============================] - 5s 7ms/step - loss: 1.0423 - accuracy: 0.5879 - val_loss: 1.0224 - val_accuracy: 0.5881\n",
            "Epoch 8/10\n",
            "703/703 [==============================] - 5s 7ms/step - loss: 1.0208 - accuracy: 0.6003 - val_loss: 1.0067 - val_accuracy: 0.5933\n",
            "Epoch 9/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.0019 - accuracy: 0.6113 - val_loss: 0.9629 - val_accuracy: 0.6214\n",
            "Epoch 10/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 0.9890 - accuracy: 0.6121 - val_loss: 0.9539 - val_accuracy: 0.6257\n",
            "[0.8400791883468628, 0.6867326498031616]\n",
            "total_pruned, after retraining pruned: 361207\n",
            "total_trainable_params_original, after retraining pruned: 592933\n",
            "fraction pruned, after retraining pruned: 0.6091868727158043\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5189c66b-a8c0-4eac-9dad-b1476316e88d\", \"my_model_weights_network_slimming_cutoff_gamma_0.995470232433743.h5\", 2407040)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 4ms/step - loss: 0.9539 - accuracy: 0.6257\n",
            "finished cutoff_gamma =  0.995470232433743\n",
            "________________________________________________\n",
            "cutoff_gamma =  1.0106475551923115\n",
            "nonzero_params_before 896\n",
            "nonzero_params_after 392\n",
            "nonzero_params_before 9248\n",
            "nonzero_params_after 3468\n",
            "nonzero_params_before 18496\n",
            "nonzero_params_after 6358\n",
            "nonzero_params_before 36928\n",
            "nonzero_params_after 12117\n",
            "nonzero_params_before 524800\n",
            "nonzero_params_after 82000\n",
            "nonzero_params_before 2565\n",
            "nonzero_params_after 2565\n",
            "total_pruned: 486033\n",
            "total_trainable_params_original: 592933\n",
            "fraction pruned: 0.8197098154428916\n",
            "Epoch 1/10\n",
            "703/703 [==============================] - 7s 7ms/step - loss: 1.5446 - accuracy: 0.2911 - val_loss: 1.4746 - val_accuracy: 0.3311\n",
            "Epoch 2/10\n",
            "703/703 [==============================] - 5s 7ms/step - loss: 1.4375 - accuracy: 0.3658 - val_loss: 1.3671 - val_accuracy: 0.3980\n",
            "Epoch 3/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.3751 - accuracy: 0.4066 - val_loss: 1.3063 - val_accuracy: 0.4321\n",
            "Epoch 4/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.3339 - accuracy: 0.4277 - val_loss: 1.2796 - val_accuracy: 0.4487\n",
            "Epoch 5/10\n",
            "703/703 [==============================] - 6s 8ms/step - loss: 1.3063 - accuracy: 0.4508 - val_loss: 1.2608 - val_accuracy: 0.4626\n",
            "Epoch 6/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.2863 - accuracy: 0.4599 - val_loss: 1.2319 - val_accuracy: 0.4848\n",
            "Epoch 7/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.2692 - accuracy: 0.4687 - val_loss: 1.2135 - val_accuracy: 0.4907\n",
            "Epoch 8/10\n",
            "703/703 [==============================] - 5s 7ms/step - loss: 1.2555 - accuracy: 0.4788 - val_loss: 1.2005 - val_accuracy: 0.4974\n",
            "Epoch 9/10\n",
            "703/703 [==============================] - 5s 7ms/step - loss: 1.2445 - accuracy: 0.4851 - val_loss: 1.1858 - val_accuracy: 0.5069\n",
            "Epoch 10/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.2377 - accuracy: 0.4899 - val_loss: 1.1875 - val_accuracy: 0.5014\n",
            "[0.953850269317627, 0.6257425546646118]\n",
            "total_pruned, after retraining pruned: 486033\n",
            "total_trainable_params_original, after retraining pruned: 592933\n",
            "fraction pruned, after retraining pruned: 0.8197098154428916\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e671a707-c184-4431-bc37-e19c6f76638d\", \"my_model_weights_network_slimming_cutoff_gamma_1.0106475551923115.h5\", 2407040)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 4ms/step - loss: 1.1875 - accuracy: 0.5014\n",
            "finished cutoff_gamma =  1.0106475551923115\n",
            "________________________________________________\n",
            "cutoff_gamma =  1.0258248779508803\n",
            "nonzero_params_before 896\n",
            "nonzero_params_after 280\n",
            "nonzero_params_before 9248\n",
            "nonzero_params_after 2312\n",
            "nonzero_params_before 18496\n",
            "nonzero_params_after 4335\n",
            "nonzero_params_before 36928\n",
            "nonzero_params_after 5770\n",
            "nonzero_params_before 524800\n",
            "nonzero_params_after 25625\n",
            "nonzero_params_before 2565\n",
            "nonzero_params_after 2565\n",
            "total_pruned: 552046\n",
            "total_trainable_params_original: 592933\n",
            "fraction pruned: 0.9310427991020908\n",
            "Epoch 1/10\n",
            "703/703 [==============================] - 7s 8ms/step - loss: 1.5994 - accuracy: 0.2241 - val_loss: 1.5612 - val_accuracy: 0.2978\n",
            "Epoch 2/10\n",
            "703/703 [==============================] - 5s 7ms/step - loss: 1.5508 - accuracy: 0.2800 - val_loss: 1.5158 - val_accuracy: 0.3121\n",
            "Epoch 3/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.5198 - accuracy: 0.3061 - val_loss: 1.4809 - val_accuracy: 0.3315\n",
            "Epoch 4/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.4941 - accuracy: 0.3210 - val_loss: 1.4554 - val_accuracy: 0.3501\n",
            "Epoch 5/10\n",
            "703/703 [==============================] - 5s 8ms/step - loss: 1.4739 - accuracy: 0.3319 - val_loss: 1.4340 - val_accuracy: 0.3564\n",
            "Epoch 6/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.4587 - accuracy: 0.3468 - val_loss: 1.4233 - val_accuracy: 0.3592\n",
            "Epoch 7/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.4481 - accuracy: 0.3473 - val_loss: 1.4128 - val_accuracy: 0.3671\n",
            "Epoch 8/10\n",
            "703/703 [==============================] - 5s 8ms/step - loss: 1.4449 - accuracy: 0.3511 - val_loss: 1.4012 - val_accuracy: 0.3747\n",
            "Epoch 9/10\n",
            "703/703 [==============================] - 5s 7ms/step - loss: 1.4382 - accuracy: 0.3586 - val_loss: 1.3961 - val_accuracy: 0.3691\n",
            "Epoch 10/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.4291 - accuracy: 0.3583 - val_loss: 1.3919 - val_accuracy: 0.3675\n",
            "[1.1874815225601196, 0.5013861656188965]\n",
            "total_pruned, after retraining pruned: 552046\n",
            "total_trainable_params_original, after retraining pruned: 592933\n",
            "fraction pruned, after retraining pruned: 0.9310427991020908\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_275069dc-3237-4633-8a55-32af12495cec\", \"my_model_weights_network_slimming_cutoff_gamma_1.0258248779508803.h5\", 2407040)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 4ms/step - loss: 1.3919 - accuracy: 0.3675\n",
            "finished cutoff_gamma =  1.0258248779508803\n",
            "________________________________________________\n",
            "cutoff_gamma =  1.0410022007094488\n",
            "nonzero_params_before 896\n",
            "nonzero_params_after 252\n",
            "nonzero_params_before 9248\n",
            "nonzero_params_after 1156\n",
            "nonzero_params_before 18496\n",
            "nonzero_params_after 2601\n",
            "nonzero_params_before 36928\n",
            "nonzero_params_after 1731\n",
            "nonzero_params_before 524800\n",
            "nonzero_params_after 11275\n",
            "nonzero_params_before 2565\n",
            "nonzero_params_after 2565\n",
            "total_pruned: 573353\n",
            "total_trainable_params_original: 592933\n",
            "fraction pruned: 0.9669777192364062\n",
            "Epoch 1/10\n",
            "703/703 [==============================] - 7s 8ms/step - loss: 1.6094 - accuracy: 0.2156 - val_loss: 1.6080 - val_accuracy: 0.2416\n",
            "Epoch 2/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.6004 - accuracy: 0.2344 - val_loss: 1.5886 - val_accuracy: 0.2606\n",
            "Epoch 3/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.5909 - accuracy: 0.2590 - val_loss: 1.5798 - val_accuracy: 0.2729\n",
            "Epoch 4/10\n",
            "703/703 [==============================] - 5s 7ms/step - loss: 1.5828 - accuracy: 0.2663 - val_loss: 1.5666 - val_accuracy: 0.2943\n",
            "Epoch 5/10\n",
            "703/703 [==============================] - 5s 7ms/step - loss: 1.5724 - accuracy: 0.2740 - val_loss: 1.5639 - val_accuracy: 0.2919\n",
            "Epoch 6/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.5622 - accuracy: 0.2873 - val_loss: 1.5414 - val_accuracy: 0.3232\n",
            "Epoch 7/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.5530 - accuracy: 0.2857 - val_loss: 1.5320 - val_accuracy: 0.3386\n",
            "Epoch 8/10\n",
            "703/703 [==============================] - 6s 8ms/step - loss: 1.5417 - accuracy: 0.2970 - val_loss: 1.5253 - val_accuracy: 0.3299\n",
            "Epoch 9/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.5316 - accuracy: 0.3065 - val_loss: 1.5153 - val_accuracy: 0.3283\n",
            "Epoch 10/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.5272 - accuracy: 0.3023 - val_loss: 1.4986 - val_accuracy: 0.3418\n",
            "[1.391942024230957, 0.36752474308013916]\n",
            "total_pruned, after retraining pruned: 573353\n",
            "total_trainable_params_original, after retraining pruned: 592933\n",
            "fraction pruned, after retraining pruned: 0.9669777192364062\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2bb5da6f-a655-416c-bd09-2f9f63356b6c\", \"my_model_weights_network_slimming_cutoff_gamma_1.0410022007094488.h5\", 2407040)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 4ms/step - loss: 1.4986 - accuracy: 0.3418\n",
            "finished cutoff_gamma =  1.0410022007094488\n",
            "________________________________________________\n",
            "cutoff_gamma =  1.0561795234680176\n",
            "nonzero_params_before 896\n",
            "nonzero_params_after 140\n",
            "nonzero_params_before 9248\n",
            "nonzero_params_after 578\n",
            "nonzero_params_before 18496\n",
            "nonzero_params_after 1156\n",
            "nonzero_params_before 36928\n",
            "nonzero_params_after 1154\n",
            "nonzero_params_before 524800\n",
            "nonzero_params_after 1025\n",
            "nonzero_params_before 2565\n",
            "nonzero_params_after 2565\n",
            "total_pruned: 586315\n",
            "total_trainable_params_original: 592933\n",
            "fraction pruned: 0.988838536563153\n",
            "Epoch 1/10\n",
            "703/703 [==============================] - 8s 8ms/step - loss: 1.6095 - accuracy: 0.1963 - val_loss: 1.6095 - val_accuracy: 0.2115\n",
            "Epoch 2/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.6093 - accuracy: 0.2153 - val_loss: 1.6090 - val_accuracy: 0.2321\n",
            "Epoch 3/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.6074 - accuracy: 0.2179 - val_loss: 1.6033 - val_accuracy: 0.2669\n",
            "Epoch 4/10\n",
            "703/703 [==============================] - 5s 8ms/step - loss: 1.6027 - accuracy: 0.2314 - val_loss: 1.5977 - val_accuracy: 0.2697\n",
            "Epoch 5/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.6015 - accuracy: 0.2297 - val_loss: 1.5959 - val_accuracy: 0.2618\n",
            "Epoch 6/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.5992 - accuracy: 0.2312 - val_loss: 1.5937 - val_accuracy: 0.2634\n",
            "Epoch 7/10\n",
            "703/703 [==============================] - 5s 7ms/step - loss: 1.5983 - accuracy: 0.2321 - val_loss: 1.5925 - val_accuracy: 0.2685\n",
            "Epoch 8/10\n",
            "703/703 [==============================] - 5s 7ms/step - loss: 1.5976 - accuracy: 0.2319 - val_loss: 1.5908 - val_accuracy: 0.2681\n",
            "Epoch 9/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.5983 - accuracy: 0.2297 - val_loss: 1.5920 - val_accuracy: 0.2642\n",
            "Epoch 10/10\n",
            "703/703 [==============================] - 4s 6ms/step - loss: 1.5971 - accuracy: 0.2327 - val_loss: 1.5899 - val_accuracy: 0.2677\n",
            "[1.4985854625701904, 0.34178218245506287]\n",
            "total_pruned, after retraining pruned: 586315\n",
            "total_trainable_params_original, after retraining pruned: 592933\n",
            "fraction pruned, after retraining pruned: 0.988838536563153\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ce33aaca-c7f5-4c41-9306-4af3077d2996\", \"my_model_weights_network_slimming_cutoff_gamma_1.0561795234680176.h5\", 2407040)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 5ms/step - loss: 1.5899 - accuracy: 0.2677\n",
            "finished cutoff_gamma =  1.0561795234680176\n",
            "________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sparsity_vs_accuracy_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EEykicSs-KS",
        "outputId": "df0bd95d-c6c3-4f92-8dc3-42b99b61c6cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.7251484990119934, 0.0024825739164458715, 0.9195836186408997),\n",
              " (0.7302970290184021, 0.00749494462274827, 0.9347609413994683),\n",
              " (0.7223762273788452, 0.0662671836446951, 0.949938264158037),\n",
              " (0.6986138820648193, 0.19055609993034625, 0.9651155869166056),\n",
              " (0.6867326498031616, 0.4045448642595369, 0.9802929096751742),\n",
              " (0.6257425546646118, 0.6091868727158043, 0.995470232433743),\n",
              " (0.5013861656188965, 0.8197098154428916, 1.0106475551923115),\n",
              " (0.36752474308013916, 0.9310427991020908, 1.0258248779508803),\n",
              " (0.34178218245506287, 0.9669777192364062, 1.0410022007094488),\n",
              " (0.2677227854728699, 0.988838536563153, 1.0561795234680176)]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(sparsity_vs_accuracy_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXyaJjj2tD30",
        "outputId": "238eb59e-6e72-42f4-8437-ddb58e22ae5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7251485 , 0.00248257, 0.91958362],\n",
              "       [0.73029703, 0.00749494, 0.93476094],\n",
              "       [0.72237623, 0.06626718, 0.94993826],\n",
              "       [0.69861388, 0.1905561 , 0.96511559],\n",
              "       [0.68673265, 0.40454486, 0.98029291],\n",
              "       [0.62574255, 0.60918687, 0.99547023],\n",
              "       [0.50138617, 0.81970982, 1.01064756],\n",
              "       [0.36752474, 0.9310428 , 1.02582488],\n",
              "       [0.34178218, 0.96697772, 1.0410022 ],\n",
              "       [0.26772279, 0.98883854, 1.05617952]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.savetxt(\"sparsity_vs_accuracy_list.txt\",np.array(sparsity_vs_accuracy_list))\n",
        "files.download(\"sparsity_vs_accuracy_list.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "FO1b8f2JtMRH",
        "outputId": "dab090f9-62a2-4063-8554-4e65f6f0a30e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_931ca330-c9bd-469a-aec6-ab692c34c9c7\", \"sparsity_vs_accuracy_list.txt\", 750)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(weights))\n",
        "print([weights[i].shape for i in range(len(weights))])"
      ],
      "metadata": {
        "id": "XPdkWCoG4cL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "gH8C8l-x4p_m",
        "outputId": "6c0d51e1-0374-4068-fdaa-ec9e41531dd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 25, 25, 32)        896       \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 25, 25, 32)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 23, 23, 32)        9248      \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 23, 23, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 11, 11, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 11, 11, 32)        0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 11, 11, 64)        0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 9, 9, 64)          36928     \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 9, 9, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 4, 4, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 592933 (2.26 MB)\n",
            "Trainable params: 592933 (2.26 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUuNXFjV4T-E",
        "outputId": "d9cac879-0f2d-49cd-b689-bb8190c9cc3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# evaluate again to see how the accuracy changes\n",
        "results = model.evaluate(val_images, val_labels, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 7s 13ms/step - loss: 0.7373 - accuracy: 0.7180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2qckI6uj3JR",
        "outputId": "81f75fe3-1acb-499c-fcaa-9df5ac9a9582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7180197834968567"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMSKQW4k4T-G",
        "outputId": "e375d7fb-6289-42d6-9096-3e0e673869b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "# you need to save the model's weights, naming it 'my_model_weights.h5'\n",
        "model.save_weights(\"my_model_weights.h5\")\n",
        "\n",
        "# running this cell will immediately download a file called 'my_model_weights.h5'\n",
        "from google.colab import files\n",
        "files.download(\"my_model_weights.h5\")\n",
        "\n",
        "cutoff_gamma = 10\n",
        "save_name = f\"my_model_weights_network_slimming_cutoff_gamma_{cutoff_gamma}.h5\"\n",
        "model.save_weights(save_name)\n",
        "files.download(save_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0781a71c-abcc-4a69-900e-58e9379407d0\", \"my_model_weights.h5\", 2407040)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4deb332e-8c3f-4a73-a4e5-8ae50f0258ad\", \"my_model_weights_network_slimming_cutoff_gamma_10.h5\", 2407040)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, weight_decay=1e-6),\n",
        "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "#                 metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# model.load_weights('./my_model_weights_2.h5', skip_mismatch=False)\n",
        "\n",
        "# # evaluate again to see how the accuracy changes\n",
        "# results = model.evaluate(val_images, val_labels, batch_size=128)\n",
        "# accuracy = results[1]"
      ],
      "metadata": {
        "id": "jt2T7CDPyIsl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d752df9-f07f-4fe5-b729-d4db2d59e772"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 7s 11ms/step - loss: 0.7970 - accuracy: 0.6966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# num_weights = 0\n",
        "# num_nonzeros = 0\n",
        "# for t in model.get_weights():\n",
        "#    num_weights += np.prod(t.shape)\n",
        "#    num_nonzeros += np.count_nonzero(t)\n",
        "\n",
        "\n",
        "# sparse = 1 - num_nonzeros/num_weights\n",
        "# print(sparse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4cLCsdIcJ2D",
        "outputId": "ebeb8d2b-e99c-4462-9fb4-cf23620a9e06"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6817448177112759\n"
          ]
        }
      ]
    }
  ]
}