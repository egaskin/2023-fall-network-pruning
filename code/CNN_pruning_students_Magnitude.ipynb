{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-eC-sb34T9w"
      },
      "source": [
        "## Accelerate Inference: Neural Network Pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L47XBZWm4T9x",
        "outputId": "d051adca-962a-4b32-fe8e-78ad68477c5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\tzhan\\PythonWS\\10605_Fall2023\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models, regularizers\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "print(tf.version.VERSION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1FQTVeAuNiU",
        "outputId": "18dffec4-837a-40ac-d16b-b954a2ea7158"
      },
      "outputs": [],
      "source": [
        "# untar\n",
        "# !tar -xvzf dataset.tar.gz\n",
        "# load train\n",
        "train_images = pickle.load(open('train_images.pkl', 'rb'))\n",
        "train_labels = pickle.load(open('train_labels.pkl', 'rb'))\n",
        "# load val\n",
        "val_images = pickle.load(open('val_images.pkl', 'rb'))\n",
        "val_labels = pickle.load(open('val_labels.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KE9JuZDG4T94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\tzhan\\PythonWS\\10605_Fall2023\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\tzhan\\PythonWS\\10605_Fall2023\\venv\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define the neural network architecture (don't change this)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-5), input_shape=(25,25,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5))\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTzcSoYl4T97",
        "outputId": "dc9e6a38-f0f5-4e29-f203-2a15864b9338"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 25, 25, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 25, 25, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 23, 23, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 23, 23, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 11, 11, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 11, 11, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 11, 11, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 9, 9, 64)          36928     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 9, 9, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 4, 4, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               524800    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 592933 (2.26 MB)\n",
            "Trainable params: 592933 (2.26 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9Nk_MAPqZPt",
        "outputId": "04d67cb5-7302-402d-cc45-df65741288d5"
      },
      "outputs": [],
      "source": [
        "# you can use the default hyper-parameters for training,\n",
        "# val accuracy ~72% after 50 epochs\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, weight_decay=1e-6),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# history = model.fit(train_images, train_labels, batch_size=32, epochs=50,\n",
        "#                     validation_data=(val_images, val_labels)) # train for 50 epochs, with batch size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOhpP7M24T9_",
        "outputId": "843ee056-cb7a-42b9-91b9-27a884f5a32c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\tzhan\\PythonWS\\10605_Fall2023\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\tzhan\\PythonWS\\10605_Fall2023\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "20/20 [==============================] - 1s 14ms/step - loss: 1.6110 - accuracy: 0.2075\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(val_images, val_labels, batch_size=128)\n",
        "# model.save('local_model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import copy\n",
        "def GetSparsity(model):\n",
        "  temp_weights = copy.deepcopy(model.get_weights())\n",
        "  num_weights = 0\n",
        "  num_nonzeros = 0\n",
        "  for t in temp_weights:\n",
        "    num_weights += np.prod(t.shape)\n",
        "    num_nonzeros += np.count_nonzero(t)\n",
        "\n",
        "\n",
        "  sparse = 1 - num_nonzeros/num_weights\n",
        "  return sparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "def magnitude_prune(train_images, train_labels, val_images, val_labels,model):\n",
        "  batch_size = 32\n",
        "  num_epoch = 0\n",
        "  num_increments = 10\n",
        "\n",
        "  A = copy.deepcopy(model.weights)\n",
        "  sparsity = []\n",
        "  accuracy = []\n",
        "  rand_idxs = np.arange(train_images.shape[0])\n",
        "  num_batches = int(np.ceil(train_images.shape[0]/batch_size))\n",
        "\n",
        "  for i in range(num_increments):\n",
        "    all_masks = {}\n",
        "    for j in [8, 10]:\n",
        "      max_mag = np.max(np.abs(A[j]))\n",
        "      thresh = i/num_increments*max_mag\n",
        "      mask = np.array(np.abs(A[j]) > thresh).astype(int)\n",
        "      all_masks[j] = mask\n",
        "\n",
        "    np.random.shuffle(rand_idxs)\n",
        "    model.set_weights(A)\n",
        "    B = copy.deepcopy(model.weights)\n",
        "    for key in all_masks:\n",
        "      B[key] = B[key]*all_masks[key]\n",
        "    model.set_weights(B)\n",
        "\n",
        "    for j in range(num_epoch):\n",
        "      print(i, 'epoch', j)\n",
        "      # for k in range(num_batches):\n",
        "      #   if k == num_batches-1:\n",
        "      #     batch_x = train_images[rand_idxs[k*batch_size:]]\n",
        "      #     batch_y = train_labels[rand_idxs[k*batch_size:]]\n",
        "      #   else:\n",
        "      #     batch_x = train_images[rand_idxs[k*batch_size: (k+1)*batch_size]]\n",
        "      #     batch_y = train_labels[rand_idxs[k*batch_size: (k+1)*batch_size]]\n",
        "      model.fit(train_images, train_labels, batch_size = 32, verbose = 0)\n",
        "\n",
        "      #   model.fit(batch_x, batch_y, verbose = 0)\n",
        "      B = copy.deepcopy(model.weights)\n",
        "      for key in all_masks:\n",
        "        B[key] = B[key]*all_masks[key]\n",
        "      model.set_weights(B)\n",
        "      #   del B, batch_x, batch_y\n",
        "      # model.evaluate(val_images, val_labels)\n",
        "    B = copy.deepcopy(model.weights)\n",
        "    for key in all_masks:\n",
        "      B[key] = B[key]*all_masks[key]\n",
        "    model.set_weights(B)\n",
        "    del B\n",
        "    _, acc = model.evaluate(val_images, val_labels)\n",
        "    sparsity.append(GetSparsity(model))\n",
        "    accuracy.append(acc)\n",
        "  return (sparsity, accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "import copy\n",
        "def progressive_magnitude(train_images, train_labels, val_images, val_labels,model):\n",
        "  batch_size = 32\n",
        "  num_iterations = 7\n",
        "  step_size = 0.1\n",
        "\n",
        "  A = copy.deepcopy(model.weights)\n",
        "  sparsity = []\n",
        "  accuracy = []\n",
        "  rand_idxs = np.arange(train_images.shape[0])\n",
        "  num_batches = int(np.ceil(train_images.shape[0]/batch_size))\n",
        "\n",
        "  original_loss = model.evaluate(train_images, train_labels)\n",
        "  original_loss = original_loss[0]\n",
        "  print('Original Loss', original_loss)\n",
        "\n",
        "  for i in range(num_iterations):\n",
        "    all_masks = {}\n",
        "    for j in [8, 10]:\n",
        "      max_mag = np.max(np.abs(model.weights[j]))\n",
        "      thresh = i*step_size*max_mag\n",
        "      mask = np.array(np.abs(model.weights[j]) > thresh).astype(int)\n",
        "      all_masks[j] = mask\n",
        "\n",
        "    np.random.shuffle(rand_idxs)\n",
        "    B = copy.deepcopy(model.weights)\n",
        "    for key in all_masks:\n",
        "      B[key] = B[key]*all_masks[key]\n",
        "    model.set_weights(B)\n",
        "    del B\n",
        "    new_loss = model.evaluate(train_images, train_labels, verbose = 0)\n",
        "    new_loss = new_loss[0]\n",
        "    print('Init Loss after pruning: ', new_loss)\n",
        "    print('Sparsity: ', GetSparsity(model))\n",
        "    j = 0\n",
        "    while new_loss > (1.1 + i*0.1)*original_loss:\n",
        "      print(i, 'epoch', j)\n",
        "      for k in range(num_batches):\n",
        "        if k == num_batches-1:\n",
        "          batch_x = train_images[rand_idxs[k*batch_size:]]\n",
        "          batch_y = train_labels[rand_idxs[k*batch_size:]]\n",
        "        else:\n",
        "          batch_x = train_images[rand_idxs[k*batch_size: (k+1)*batch_size]]\n",
        "          batch_y = train_labels[rand_idxs[k*batch_size: (k+1)*batch_size]]\n",
        "          \n",
        "        model.fit(batch_x, batch_y, verbose = 0)\n",
        "        B = copy.deepcopy(model.weights)\n",
        "        for key in all_masks:\n",
        "          B[key] = B[key]*all_masks[key]\n",
        "        model.set_weights(B)\n",
        "        del B, batch_x, batch_y\n",
        "      # model.fit(train_images, train_labels, epochs=1, batch_size = 32)\n",
        "      # B = copy.deepcopy(model.weights)\n",
        "      # for key in all_masks:\n",
        "      #   B[key] = B[key]*all_masks[key]\n",
        "      # model.set_weights(B)\n",
        "      # del B\n",
        "      new_loss = model.evaluate(train_images, train_labels)\n",
        "      new_loss = new_loss[0]\n",
        "      j += 1\n",
        "      model.save_weights(f\"my_model_weights_{i}.h5\") \n",
        "\n",
        "    # B = copy.deepcopy(model.weights)\n",
        "    # for key in all_masks:\n",
        "    #   B[key] = B[key]*all_masks[key]\n",
        "    # model.set_weights(B)\n",
        "    # del B\n",
        "    # _, acc = model.evaluate(val_images, val_labels)\n",
        "    # sparsity.append(GetSparsity(model))\n",
        "    # accuracy.append(acc)\n",
        "  # return (sparsity, accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "vjw94aij4T-C"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 1s 4ms/step - loss: 0.7169 - accuracy: 0.7386\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7153 - accuracy: 0.7378\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.7241 - accuracy: 0.7354\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 0.8418 - accuracy: 0.7271\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.2244 - accuracy: 0.6879\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.4996 - accuracy: 0.4816\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.5920 - accuracy: 0.3889\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.6135 - accuracy: 0.2071\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.6132 - accuracy: 0.2071\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.6132 - accuracy: 0.1925\n"
          ]
        }
      ],
      "source": [
        "# perform pruning here\n",
        "model = keras.models.load_model('./local_model.keras')\n",
        "# model.evaluate(val_images, val_labels)\n",
        "# sparsity, acc = magnitude_prune(train_images, train_labels, val_images, val_labels, model)\n",
        "# np.savetxt('record_noTraining.csv',np.array([sparsity, acc]).T, delimiter=',')\n",
        "\n",
        "progressive_magnitude(train_images, train_labels, val_images, val_labels, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8852922674231322\n",
            "[864, 32, 9216, 32, 18432, 64, 36864, 64, 1624, 512, 305, 5]\n"
          ]
        }
      ],
      "source": [
        "print(GetSparsity(model))\n",
        "print([np.count_nonzero(x) for x in model.weights])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gH8C8l-x4p_m",
        "outputId": "1d3f2577-ee6f-48d9-ea6e-763a1e225d44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 25, 25, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 25, 25, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 23, 23, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 23, 23, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 11, 11, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 11, 11, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 11, 11, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 9, 9, 64)          36928     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 9, 9, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 4, 4, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               524800    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 592933 (2.26 MB)\n",
            "Trainable params: 592933 (2.26 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 0s 10ms/step - loss: 0.8400 - accuracy: 0.6851\n"
          ]
        }
      ],
      "source": [
        "# evaluate again to see how the accuracy changes\n",
        "results = model.evaluate(val_images, val_labels, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.savetxt('record2.txt',np.array([sparsity, acc]).T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wMSKQW4k4T-G",
        "outputId": "1b4059fe-c34c-4f31-e813-bd8306e376cd"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\tzhan\\PythonWS\\10605_Fall2023\\Project\\CNN_pruning_students_Thomas_Zhang.ipynb Cell 16\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tzhan/PythonWS/10605_Fall2023/Project/CNN_pruning_students_Thomas_Zhang.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39msave_weights(\u001b[39m\"\u001b[39m\u001b[39mmy_model_weights.h5\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tzhan/PythonWS/10605_Fall2023/Project/CNN_pruning_students_Thomas_Zhang.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# running this cell will immediately download a file called 'my_model_weights.h5'\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tzhan/PythonWS/10605_Fall2023/Project/CNN_pruning_students_Thomas_Zhang.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m files\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tzhan/PythonWS/10605_Fall2023/Project/CNN_pruning_students_Thomas_Zhang.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m files\u001b[39m.\u001b[39mdownload(\u001b[39m\"\u001b[39m\u001b[39mmy_model_weights.h5\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "# you need to save the model's weights, naming it 'my_model_weights.h5'\n",
        "model.save_weights(\"my_model_weights.h5\")\n",
        "\n",
        "# running this cell will immediately download a file called 'my_model_weights.h5'\n",
        "# from google.colab import files\n",
        "# files.download(\"my_model_weights.h5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
